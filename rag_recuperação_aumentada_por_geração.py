# -*- coding: utf-8 -*-
"""RAG: Recupera√ß√£o Aumentada por Gera√ß√£o

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18tQqnvuqXOLSogQQeJsfoA0_xis7m0Pe

## Imports e downloads
"""

!pip install pymupdf
!pip install faiss-cpu

from google.colab import drive

import requests
import fitz  # PyMuPDF
from io import BytesIO

import re

from sentence_transformers import SentenceTransformer

import faiss

import numpy as np

from sklearn.preprocessing import normalize

"""##carregamento pdf do drive

"""

drive.mount('/content/drive')

PDF = "/content/drive/MyDrive/PDF INSTITUICAO.pdf"

"""## Criacao da funcao que vai extrair o texto do pdf PyMuPDF (fitz)

"""

def extrair_texto_pdf(PDF):
    doc = fitz.open(PDF)
    textos = [pagina.get_text() for pagina in doc]
    texto_completo = "\n".join(textos)
    return texto_completo, doc  # retorna o texto e o doc

"""## primeiros testes

"""

texto_completo, doc = extrair_texto_pdf(PDF)
# Ver quantas p√°ginas tem
print(f"O PDF tem {len(doc)} p√°ginas")

# Mostrar o conte√∫do da primeira p√°gina
print("\nConte√∫do da primeira p√°gina:\n")
print(doc[0].get_text())

"""##criacao dos chunks e testes"""

def dividir_chunks_por_aspas(texto):
    #Captura todo conte√∫do entre aspas duplas (inclusive quebra de linha)
    chunks = re.findall(r'"(.*?)"', texto, flags=re.DOTALL)
     #Remove espa√ßos extras e ignora strings vazias
    return [c.strip() for c in chunks if c.strip()]

chunks = dividir_chunks_por_aspas(texto_completo)

print(f"Total de chunks gerados: {len(chunks)}")

if len(chunks) == 0:
    print("‚ö†Ô∏è Nenhum chunk foi gerado. Verifique se o texto foi lido corretamente.")
else:
    for i in range(min(10, len(chunks))):
        print(f"üîπ \033[1m Chunk  {i+1}:\033[0m \n{chunks[i]}\n{'-'*80}")

"""## carregamento do modelo de embeddings como Sentence-BERT (SBERT). Ele converte tanto perguntas quanto textos em vetores num√©ricos que preservam similaridade sem√¢ntica."""

model = SentenceTransformer('all-MiniLM-L6-v2')
vetores = model.encode(chunks).astype("float32")
vetores = normalize(vetores, axis=1, norm='l2')

index = faiss.IndexFlatIP(vetores.shape[1])
index.add(vetores)

def recuperar_top_k(pergunta, k=1):
    vetor_pergunta = model.encode([pergunta]).astype("float32")
    vetor_pergunta = vetor_pergunta / np.linalg.norm(vetor_pergunta, axis=1, keepdims=True)  # normaliza
    distancias, indices = index.search(vetor_pergunta, k)
    return [(chunks[i], distancias[0][j]) for j, i in enumerate(indices[0])]

"""## primeiros testes modelo

"""

def imprimir_top_k_respostas(pergunta, k=1):
    vetor_pergunta = model.encode([pergunta]).astype("float32")
    vetor_pergunta = vetor_pergunta / np.linalg.norm(vetor_pergunta, axis=1, keepdims=True)
    distancias, indices = index.search(vetor_pergunta, k)

    print(f"\033[1müü• Pergunta:\033[0m {pergunta}\n")
    for i, (idx, dist) in enumerate(zip(indices[0], distancias[0])):
        print(f"\033[1müîπ Top {i+1} (Similaridade: {dist:.4f}):\033[0m")
        print(f"{chunks[idx]}\n")

perguntas = [
    "O que acontece se o aluno n√£o renovar a matr√≠cula?",
    "Onde posso renovar a matr√≠cula?",
    "O est√°gio √© obrigat√≥rio?",
    "O que diferencia um estudo EAD do estudante presencial?",
    "Quando deve ser feita a renova√ß√£o de matr√≠cula?"
]

print('='*80,"\033[1m\nIndice de Similaridade:\033[0m\n\n"
                                             "\033[1mQuanto mais proximo de -1:\033[0m Totalmente contrario\n"
                                             "\033[1mQuanto mais proximo de 0:\033[0m Sem Relacao\n"
                                             "\033[1mQuanto mais proximo de 1:\033[0m Similaridade total\n\n",'='*80)
#for pergunta in perguntas:
    #imprimir_top_k_respostas(pergunta, k=1)
    #print("\n")  # separa√ß√£o entre as perguntas

imprimir_top_k_respostas(perguntas[0], k=1)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[1], k=3)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[2], k=6)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[3], k=1)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[4], k=2)

"""## teste com outro pdf maior para teste

"""

PDF = "/content/drive/MyDrive/PDF INSTITUCIONAL 2.pdf"

texto_completo, doc = extrair_texto_pdf(PDF)
# Ver quantas p√°ginas tem
print(f"O PDF tem {len(doc)} p√°ginas")

# Mostrar o conte√∫do da primeira p√°gina
print("\nConte√∫do da primeira p√°gina:\n")
print(doc[0].get_text())

def dividir_chunks_por_ponto_final(texto):
    # Divide o texto por ponto final seguido de espa√ßo ou fim de linha
    chunks = re.split(r'\.\s*', texto)
    return [c.strip() for c in chunks if c.strip()]

chunks = dividir_chunks_por_ponto_final(texto_completo)

print(f"Total de chunks gerados: {len(chunks)}")

if len(chunks) == 0:
    print("‚ö†Ô∏è Nenhum chunk foi gerado. Verifique se o texto foi lido corretamente.")
else:
    for i in range(min(15, len(chunks))):
        print(f"üîπ \033[1m Chunk  {i+1}:\033[0m \n{chunks[i]}\n{'-'*80}")

perguntas = [
    "O que significa o termo multimodal no BLIP?",
    "O blip-vqa-base √© a vers√£o compacta de qual fam√≠lia?",
    "Por que o modelo Salesforce/blip-vqa-base foi escolhido?",
    "Qual modelo de grande porte foi citado no texto como exemplo de alternativa mais robusta, por√©m mais pesada?",
]

print('='*80,"\033[1m\nIndice de Similaridade:\033[0m\n\n"
                                             "\033[1mQuanto mais proximo de -1:\033[0m Totalmente contrario\n"
                                             "\033[1mQuanto mais proximo de 0:\033[0m Sem Relacao\n"
                                             "\033[1mQuanto mais proximo de 1:\033[0m Similaridade total\n\n",'='*80)
#for pergunta in perguntas:
   # imprimir_top_k_respostas(pergunta, k=1)
   # print("\n")  # separa√ß√£o entre as perguntas

imprimir_top_k_respostas(perguntas[0], k=1)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[1], k=1)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[2], k=1)
print("\n",('-'*80))
imprimir_top_k_respostas(perguntas[3], k=1)