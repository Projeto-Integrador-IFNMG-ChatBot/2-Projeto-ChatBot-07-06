{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports e downloads"
      ],
      "metadata": {
        "id": "3waQ0jhY70yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install faiss-cpu\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import requests\n",
        "import fitz  # PyMuPDF\n",
        "from io import BytesIO\n",
        "\n",
        "import re\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import faiss\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import normalize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ_dw9Dx7ztJ",
        "outputId": "91ca1220-c0c2-4196-bbdd-93704e6e6409",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.26.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##carregamento pdf do drive\n"
      ],
      "metadata": {
        "id": "KjuHxnGkym6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7IlinvJMRNC",
        "outputId": "8f58073e-9817-4e97-be52-542fb2bcc545",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PDF = \"/content/drive/MyDrive/PDF INSTITUICAO.pdf\""
      ],
      "metadata": {
        "id": "RX8BzOgQx0X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "71W-_4wgywO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criacao da funcao que vai extrair o texto do pdf PyMuPDF (fitz)\n"
      ],
      "metadata": {
        "id": "6KI-90J9NL2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_texto_pdf(PDF):\n",
        "    doc = fitz.open(PDF)\n",
        "    textos = [pagina.get_text() for pagina in doc]\n",
        "    texto_completo = \"\\n\".join(textos)\n",
        "    return texto_completo, doc  # retorna o texto e o doc"
      ],
      "metadata": {
        "id": "UMao3oq_zX1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## primeiros testes\n"
      ],
      "metadata": {
        "id": "ckSO3c6k1XRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_completo, doc = extrair_texto_pdf(PDF)\n",
        "# Ver quantas p√°ginas tem\n",
        "print(f\"O PDF tem {len(doc)} p√°ginas\")\n",
        "\n",
        "# Mostrar o conte√∫do da primeira p√°gina\n",
        "print(\"\\nConte√∫do da primeira p√°gina:\\n\")\n",
        "print(doc[0].get_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g_fHumyU0MQI",
        "outputId": "d0207836-2347-4313-e140-904f3b5b151c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O PDF tem 1 p√°ginas\n",
            "\n",
            "Conte√∫do da primeira p√°gina:\n",
            "\n",
            "1.‚Äã \"O ato de se matricular pode ser realizado diretamente na CRA, com ou sem \n",
            "procura√ß√£o.\" \n",
            " \n",
            "2.‚Äã \"A renova√ß√£o da matr√≠cula √© obrigat√≥ria para alunos em est√°gio \n",
            "supervisionado.\" \n",
            " \n",
            "3.‚Äã \"O projeto est√° em desenvolvimento e depende de aprova√ß√£o do comit√™.\" \n",
            " \n",
            "4.‚Äã \"A renova√ß√£o do contrato de presta√ß√£o de servi√ßos deve ser feita at√© o fim do \n",
            "semestre.\" \n",
            " \n",
            "5.‚Äã \"Quem n√£o renovar a matr√≠cula ser√° automaticamente desligado do curso.\" \n",
            " \n",
            "6.‚Äã \"Na modalidade EAD, a inscri√ß√£o √© feita por m√≥dulos, conforme regras \n",
            "espec√≠ficas da institui√ß√£o.\" \n",
            " \n",
            "7.‚Äã \"Estudantes presenciais devem se inscrever em disciplinas, respeitando o \n",
            "plano pedag√≥gico do curso.\" \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##criacao dos chunks e testes"
      ],
      "metadata": {
        "id": "ZuuVGRXJ1hJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dividir_chunks_por_aspas(texto):\n",
        "    #Captura todo conte√∫do entre aspas duplas (inclusive quebra de linha)\n",
        "    chunks = re.findall(r'\"(.*?)\"', texto, flags=re.DOTALL)\n",
        "     #Remove espa√ßos extras e ignora strings vazias\n",
        "    return [c.strip() for c in chunks if c.strip()]\n",
        "\n",
        "chunks = dividir_chunks_por_aspas(texto_completo)"
      ],
      "metadata": {
        "id": "Hc6PPkJIzdOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total de chunks gerados: {len(chunks)}\")\n",
        "\n",
        "if len(chunks) == 0:\n",
        "    print(\"‚ö†Ô∏è Nenhum chunk foi gerado. Verifique se o texto foi lido corretamente.\")\n",
        "else:\n",
        "    for i in range(min(10, len(chunks))):\n",
        "        print(f\"üîπ \\033[1m Chunk  {i+1}:\\033[0m \\n{chunks[i]}\\n{'-'*80}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51aBNkJ17m_",
        "outputId": "944aecd6-ee42-4888-a60e-f8374b5e064a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de chunks gerados: 7\n",
            "üîπ \u001b[1m Chunk  1:\u001b[0m \n",
            "O ato de se matricular pode ser realizado diretamente na CRA, com ou sem \n",
            "procura√ß√£o.\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  2:\u001b[0m \n",
            "A renova√ß√£o da matr√≠cula √© obrigat√≥ria para alunos em est√°gio \n",
            "supervisionado.\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  3:\u001b[0m \n",
            "O projeto est√° em desenvolvimento e depende de aprova√ß√£o do comit√™.\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  4:\u001b[0m \n",
            "A renova√ß√£o do contrato de presta√ß√£o de servi√ßos deve ser feita at√© o fim do \n",
            "semestre.\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  5:\u001b[0m \n",
            "Quem n√£o renovar a matr√≠cula ser√° automaticamente desligado do curso.\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  6:\u001b[0m \n",
            "Na modalidade EAD, a inscri√ß√£o √© feita por m√≥dulos, conforme regras \n",
            "espec√≠ficas da institui√ß√£o.\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  7:\u001b[0m \n",
            "Estudantes presenciais devem se inscrever em disciplinas, respeitando o \n",
            "plano pedag√≥gico do curso.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## carregamento do modelo de embeddings como Sentence-BERT (SBERT). Ele converte tanto perguntas quanto textos em vetores num√©ricos que preservam similaridade sem√¢ntica."
      ],
      "metadata": {
        "id": "NmvfRpz75v2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "vetores = model.encode(chunks).astype(\"float32\")\n",
        "vetores = normalize(vetores, axis=1, norm='l2')"
      ],
      "metadata": {
        "id": "bwOhtzlm5wkH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexFlatIP(vetores.shape[1])\n",
        "index.add(vetores)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0Qb1oFba5_vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recuperar_top_k(pergunta, k=1):\n",
        "    vetor_pergunta = model.encode([pergunta]).astype(\"float32\")\n",
        "    vetor_pergunta = vetor_pergunta / np.linalg.norm(vetor_pergunta, axis=1, keepdims=True)  # normaliza\n",
        "    distancias, indices = index.search(vetor_pergunta, k)\n",
        "    return [(chunks[i], distancias[0][j]) for j, i in enumerate(indices[0])]"
      ],
      "metadata": {
        "id": "Wx8dMfSy6TgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## primeiros testes modelo\n"
      ],
      "metadata": {
        "id": "021tiYtu6QTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imprimir_top_k_respostas(pergunta, k=1):\n",
        "    vetor_pergunta = model.encode([pergunta]).astype(\"float32\")\n",
        "    vetor_pergunta = vetor_pergunta / np.linalg.norm(vetor_pergunta, axis=1, keepdims=True)\n",
        "    distancias, indices = index.search(vetor_pergunta, k)\n",
        "\n",
        "    print(f\"\\033[1müü• Pergunta:\\033[0m {pergunta}\\n\")\n",
        "    for i, (idx, dist) in enumerate(zip(indices[0], distancias[0])):\n",
        "        print(f\"\\033[1müîπ Top {i+1} (Similaridade: {dist:.4f}):\\033[0m\")\n",
        "        print(f\"{chunks[idx]}\\n\")"
      ],
      "metadata": {
        "id": "xdVsuagq65gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perguntas = [\n",
        "    \"O que acontece se o aluno n√£o renovar a matr√≠cula?\",\n",
        "    \"Onde posso renovar a matr√≠cula?\",\n",
        "    \"O est√°gio √© obrigat√≥rio?\",\n",
        "    \"O que diferencia um estudo EAD do estudante presencial?\",\n",
        "    \"Quando deve ser feita a renova√ß√£o de matr√≠cula?\"\n",
        "]"
      ],
      "metadata": {
        "id": "S4g49nmz61ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('='*80,\"\\033[1m\\nIndice de Similaridade:\\033[0m\\n\\n\"\n",
        "                                             \"\\033[1mQuanto mais proximo de -1:\\033[0m Totalmente contrario\\n\"\n",
        "                                             \"\\033[1mQuanto mais proximo de 0:\\033[0m Sem Relacao\\n\"\n",
        "                                             \"\\033[1mQuanto mais proximo de 1:\\033[0m Similaridade total\\n\\n\",'='*80)\n",
        "#for pergunta in perguntas:\n",
        "    #imprimir_top_k_respostas(pergunta, k=1)\n",
        "    #print(\"\\n\")  # separa√ß√£o entre as perguntas\n",
        "\n",
        "imprimir_top_k_respostas(perguntas[0], k=1)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[1], k=3)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[2], k=6)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[3], k=1)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[4], k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URFcjzru6aAX",
        "outputId": "1eca31ad-45c4-42e8-fff6-76f7654f8237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================ \u001b[1m\n",
            "Indice de Similaridade:\u001b[0m\n",
            "\n",
            "\u001b[1mQuanto mais proximo de -1:\u001b[0m Totalmente contrario\n",
            "\u001b[1mQuanto mais proximo de 0:\u001b[0m Sem Relacao\n",
            "\u001b[1mQuanto mais proximo de 1:\u001b[0m Similaridade total\n",
            "\n",
            " ================================================================================\n",
            "\u001b[1müü• Pergunta:\u001b[0m O que acontece se o aluno n√£o renovar a matr√≠cula?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.7677):\u001b[0m\n",
            "Quem n√£o renovar a matr√≠cula ser√° automaticamente desligado do curso.\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m Onde posso renovar a matr√≠cula?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.7299):\u001b[0m\n",
            "Quem n√£o renovar a matr√≠cula ser√° automaticamente desligado do curso.\n",
            "\n",
            "\u001b[1müîπ Top 2 (Similaridade: 0.5186):\u001b[0m\n",
            "A renova√ß√£o da matr√≠cula √© obrigat√≥ria para alunos em est√°gio \n",
            "supervisionado.\n",
            "\n",
            "\u001b[1müîπ Top 3 (Similaridade: 0.4214):\u001b[0m\n",
            "O ato de se matricular pode ser realizado diretamente na CRA, com ou sem \n",
            "procura√ß√£o.\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m O est√°gio √© obrigat√≥rio?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.5962):\u001b[0m\n",
            "A renova√ß√£o da matr√≠cula √© obrigat√≥ria para alunos em est√°gio \n",
            "supervisionado.\n",
            "\n",
            "\u001b[1müîπ Top 2 (Similaridade: 0.5219):\u001b[0m\n",
            "Na modalidade EAD, a inscri√ß√£o √© feita por m√≥dulos, conforme regras \n",
            "espec√≠ficas da institui√ß√£o.\n",
            "\n",
            "\u001b[1müîπ Top 3 (Similaridade: 0.5187):\u001b[0m\n",
            "O projeto est√° em desenvolvimento e depende de aprova√ß√£o do comit√™.\n",
            "\n",
            "\u001b[1müîπ Top 4 (Similaridade: 0.4948):\u001b[0m\n",
            "A renova√ß√£o do contrato de presta√ß√£o de servi√ßos deve ser feita at√© o fim do \n",
            "semestre.\n",
            "\n",
            "\u001b[1müîπ Top 5 (Similaridade: 0.4626):\u001b[0m\n",
            "Estudantes presenciais devem se inscrever em disciplinas, respeitando o \n",
            "plano pedag√≥gico do curso.\n",
            "\n",
            "\u001b[1müîπ Top 6 (Similaridade: 0.4484):\u001b[0m\n",
            "Quem n√£o renovar a matr√≠cula ser√° automaticamente desligado do curso.\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m O que diferencia um estudo EAD do estudante presencial?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.6581):\u001b[0m\n",
            "Estudantes presenciais devem se inscrever em disciplinas, respeitando o \n",
            "plano pedag√≥gico do curso.\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m Quando deve ser feita a renova√ß√£o de matr√≠cula?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.6752):\u001b[0m\n",
            "Quem n√£o renovar a matr√≠cula ser√° automaticamente desligado do curso.\n",
            "\n",
            "\u001b[1müîπ Top 2 (Similaridade: 0.6622):\u001b[0m\n",
            "A renova√ß√£o do contrato de presta√ß√£o de servi√ßos deve ser feita at√© o fim do \n",
            "semestre.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## teste com outro pdf maior para teste\n"
      ],
      "metadata": {
        "id": "F6NKbjVVN2jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PDF = \"/content/drive/MyDrive/PDF INSTITUCIONAL 2.pdf\""
      ],
      "metadata": {
        "id": "q1Z2TE-UN19o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto_completo, doc = extrair_texto_pdf(PDF)\n",
        "# Ver quantas p√°ginas tem\n",
        "print(f\"O PDF tem {len(doc)} p√°ginas\")\n",
        "\n",
        "# Mostrar o conte√∫do da primeira p√°gina\n",
        "print(\"\\nConte√∫do da primeira p√°gina:\\n\")\n",
        "print(doc[0].get_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEBzv_S2PY0E",
        "outputId": "559f67a2-8825-4b35-9e70-5410c769b05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O PDF tem 2 p√°ginas\n",
            "\n",
            "Conte√∫do da primeira p√°gina:\n",
            "\n",
            "‚Äã\n",
            "O modelo Salesforce/blip-vqa-base foi escolhido por se \n",
            "apresentar como uma solu√ß√£o eficiente, leve e de alto \n",
            "desempenho para tarefas de Visual Question Answering \n",
            "(VQA) ‚Äî ou seja, ele √© capaz de interpretar informa√ß√µes \n",
            "contidas em imagens e fornecer respostas em linguagem \n",
            "natural a partir dessas informa√ß√µes. Essa capacidade √© \n",
            "fundamental em aplica√ß√µes que exigem compreens√£o visual \n",
            "aliada ao processamento textual, como assistentes \n",
            "inteligentes, sistemas de acessibilidade e ferramentas de \n",
            "automa√ß√£o de an√°lise de imagens. Multimodalidade \n",
            "Avan√ßada O BLIP (Bootstrapped Language-Image \n",
            "Pretraining) representa uma arquitetura multimodal moderna, \n",
            "projetada especificamente para integrar as √°reas de vis√£o \n",
            "computacional e processamento de linguagem natural. Esse \n",
            "modelo foi treinado utilizando grandes volumes de dados que \n",
            "combinam imagens e textos, o que o torna capaz de \n",
            "compreender o conte√∫do visual em conjunto com o contexto \n",
            "textual fornecido pelo usu√°rio. Na pr√°tica, o BLIP aceita como \n",
            "entrada uma imagem e uma pergunta textual relacionada a \n",
            "essa imagem, retornando uma resposta em linguagem \n",
            "natural. Essa resposta √© gerada com base no conte√∫do visual, \n",
            "permitindo aplica√ß√µes em cen√°rios como an√°lise de \n",
            "fotografias, entendimento de documentos escaneados e \n",
            "interpreta√ß√£o de elementos gr√°ficos. \n",
            "‚Äã\n",
            " \n",
            "‚Äã\n",
            "Alto Desempenho com Custo Computacional Moderado O \n",
            "blip-vqa-base √© a vers√£o compacta da fam√≠lia BLIP. Embora \n",
            "seja uma vers√£o \"base\", ela mant√©m um excelente equil√≠brio \n",
            "entre desempenho e custo computacional. Isso permite sua \n",
            "utiliza√ß√£o em ambientes com recursos limitados, como \n",
            "m√°quinas equipadas com GPUs de uso geral ou mesmo em \n",
            "algumas aplica√ß√µes em nuvem com restri√ß√µes or√ßament√°rias. \n",
            "Em compara√ß√£o com modelos muito maiores, como o \n",
            "idefics-80b, que exigem dezenas ou centenas de gigabytes \n",
            "de mem√≥ria e infraestrutura de alto custo, o blip-vqa-base \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dividir_chunks_por_ponto_final(texto):\n",
        "    # Divide o texto por ponto final seguido de espa√ßo ou fim de linha\n",
        "    chunks = re.split(r'\\.\\s*', texto)\n",
        "    return [c.strip() for c in chunks if c.strip()]"
      ],
      "metadata": {
        "id": "blN7C8mSOHHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = dividir_chunks_por_ponto_final(texto_completo)"
      ],
      "metadata": {
        "id": "TexxYy24QV6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total de chunks gerados: {len(chunks)}\")\n",
        "\n",
        "if len(chunks) == 0:\n",
        "    print(\"‚ö†Ô∏è Nenhum chunk foi gerado. Verifique se o texto foi lido corretamente.\")\n",
        "else:\n",
        "    for i in range(min(15, len(chunks))):\n",
        "        print(f\"üîπ \\033[1m Chunk  {i+1}:\\033[0m \\n{chunks[i]}\\n{'-'*80}\")"
      ],
      "metadata": {
        "id": "0mBt182HOXkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e714c2d-dbbc-4c63-e0aa-08b6cec004c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de chunks gerados: 15\n",
            "üîπ \u001b[1m Chunk  1:\u001b[0m \n",
            "‚Äã\n",
            "O modelo Salesforce/blip-vqa-base foi escolhido por se \n",
            "apresentar como uma solu√ß√£o eficiente, leve e de alto \n",
            "desempenho para tarefas de Visual Question Answering \n",
            "(VQA) ‚Äî ou seja, ele √© capaz de interpretar informa√ß√µes \n",
            "contidas em imagens e fornecer respostas em linguagem \n",
            "natural a partir dessas informa√ß√µes\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  2:\u001b[0m \n",
            "Essa capacidade √© \n",
            "fundamental em aplica√ß√µes que exigem compreens√£o visual \n",
            "aliada ao processamento textual, como assistentes \n",
            "inteligentes, sistemas de acessibilidade e ferramentas de \n",
            "automa√ß√£o de an√°lise de imagens\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  3:\u001b[0m \n",
            "Multimodalidade \n",
            "Avan√ßada O BLIP (Bootstrapped Language-Image \n",
            "Pretraining) representa uma arquitetura multimodal moderna, \n",
            "projetada especificamente para integrar as √°reas de vis√£o \n",
            "computacional e processamento de linguagem natural\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  4:\u001b[0m \n",
            "Esse \n",
            "modelo foi treinado utilizando grandes volumes de dados que \n",
            "combinam imagens e textos, o que o torna capaz de \n",
            "compreender o conte√∫do visual em conjunto com o contexto \n",
            "textual fornecido pelo usu√°rio\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  5:\u001b[0m \n",
            "Na pr√°tica, o BLIP aceita como \n",
            "entrada uma imagem e uma pergunta textual relacionada a \n",
            "essa imagem, retornando uma resposta em linguagem \n",
            "natural\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  6:\u001b[0m \n",
            "Essa resposta √© gerada com base no conte√∫do visual, \n",
            "permitindo aplica√ß√µes em cen√°rios como an√°lise de \n",
            "fotografias, entendimento de documentos escaneados e \n",
            "interpreta√ß√£o de elementos gr√°ficos\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  7:\u001b[0m \n",
            "‚Äã\n",
            " \n",
            "‚Äã\n",
            "Alto Desempenho com Custo Computacional Moderado O \n",
            "blip-vqa-base √© a vers√£o compacta da fam√≠lia BLIP\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  8:\u001b[0m \n",
            "Embora \n",
            "seja uma vers√£o \"base\", ela mant√©m um excelente equil√≠brio \n",
            "entre desempenho e custo computacional\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  9:\u001b[0m \n",
            "Isso permite sua \n",
            "utiliza√ß√£o em ambientes com recursos limitados, como \n",
            "m√°quinas equipadas com GPUs de uso geral ou mesmo em \n",
            "algumas aplica√ß√µes em nuvem com restri√ß√µes or√ßament√°rias\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  10:\u001b[0m \n",
            "Em compara√ß√£o com modelos muito maiores, como o \n",
            "idefics-80b, que exigem dezenas ou centenas de gigabytes \n",
            "de mem√≥ria e infraestrutura de alto custo, o blip-vqa-base \n",
            "\n",
            "oferece uma alternativa muito mais acess√≠vel para \n",
            "desenvolvedores e pesquisadores que buscam implementar \n",
            "solu√ß√µes de VQA em escala menor ou de forma prototipada\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  11:\u001b[0m \n",
            "‚Äã\n",
            " \n",
            "‚Äã\n",
            "Limita√ß√µes Identificadas Durante a experimenta√ß√£o, o modelo \n",
            "demonstrou bom desempenho ao avaliar imagens e \n",
            "responder a perguntas relacionadas a cen√°rios simples, \n",
            "imagens isoladas ou conte√∫dos visuais com baixa \n",
            "complexidade informacional\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  12:\u001b[0m \n",
            "No entanto, ao aplicar o modelo \n",
            "a casos mais estruturados e espec√≠ficos ‚Äî como imagens \n",
            "contendo tabelas, quadros de hor√°rios ou planilhas com \n",
            "informa√ß√µes organizadas em grades ‚Äî foi observada uma \n",
            "redu√ß√£o significativa na capacidade de compreens√£o e \n",
            "precis√£o das respostas\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  13:\u001b[0m \n",
            "Esse comportamento ocorre porque, \n",
            "apesar da robustez do BLIP em cen√°rios gerais de VQA, sua \n",
            "arquitetura n√£o foi otimizada especificamente para lidar com \n",
            "informa√ß√µes estruturadas e densas como tabelas, que exigem \n",
            "uma leitura mais pr√≥xima de um OCR (Reconhecimento \n",
            "√ìptico de Caracteres) aliado a um racioc√≠nio l√≥gico \n",
            "estruturado\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  14:\u001b[0m \n",
            "Considera√ß√µes Finais Portanto, embora o \n",
            "blip-vqa-base se apresente como uma solu√ß√£o eficiente, \n",
            "pr√°tica e com bom custo-benef√≠cio para aplica√ß√µes gerais de \n",
            "VQA, √© importante reconhecer suas limita√ß√µes ao lidar com \n",
            "conte√∫dos altamente estruturados, como tabelas e planilhas\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ \u001b[1m Chunk  15:\u001b[0m \n",
            "Nesses casos, pode ser necess√°rio complementar o pipeline \n",
            "com ferramentas especializadas em leitura de tabelas ou \n",
            "recorrer a modelos mais robustos e pesados, caso o requisito \n",
            "de precis√£o seja elevado\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perguntas = [\n",
        "    \"O que significa o termo multimodal no BLIP?\",\n",
        "    \"O blip-vqa-base √© a vers√£o compacta de qual fam√≠lia?\",\n",
        "    \"Por que o modelo Salesforce/blip-vqa-base foi escolhido?\",\n",
        "    \"Qual modelo de grande porte foi citado no texto como exemplo de alternativa mais robusta, por√©m mais pesada?\",\n",
        "]"
      ],
      "metadata": {
        "id": "xjQruvNLO_-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('='*80,\"\\033[1m\\nIndice de Similaridade:\\033[0m\\n\\n\"\n",
        "                                             \"\\033[1mQuanto mais proximo de -1:\\033[0m Totalmente contrario\\n\"\n",
        "                                             \"\\033[1mQuanto mais proximo de 0:\\033[0m Sem Relacao\\n\"\n",
        "                                             \"\\033[1mQuanto mais proximo de 1:\\033[0m Similaridade total\\n\\n\",'='*80)\n",
        "#for pergunta in perguntas:\n",
        "   # imprimir_top_k_respostas(pergunta, k=1)\n",
        "   # print(\"\\n\")  # separa√ß√£o entre as perguntas\n",
        "\n",
        "imprimir_top_k_respostas(perguntas[0], k=1)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[1], k=1)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[2], k=1)\n",
        "print(\"\\n\",('-'*80))\n",
        "imprimir_top_k_respostas(perguntas[3], k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruqpj99QRC7f",
        "outputId": "abe23c79-08d1-4e11-b4b5-f6be30b77b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================ \u001b[1m\n",
            "Indice de Similaridade:\u001b[0m\n",
            "\n",
            "\u001b[1mQuanto mais proximo de -1:\u001b[0m Totalmente contrario\n",
            "\u001b[1mQuanto mais proximo de 0:\u001b[0m Sem Relacao\n",
            "\u001b[1mQuanto mais proximo de 1:\u001b[0m Similaridade total\n",
            "\n",
            " ================================================================================\n",
            "\u001b[1müü• Pergunta:\u001b[0m O que significa o termo multimodal no BLIP?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.4598):\u001b[0m\n",
            "Multimodalidade \n",
            "Avan√ßada O BLIP (Bootstrapped Language-Image \n",
            "Pretraining) representa uma arquitetura multimodal moderna, \n",
            "projetada especificamente para integrar as √°reas de vis√£o \n",
            "computacional e processamento de linguagem natural\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m O blip-vqa-base √© a vers√£o compacta de qual fam√≠lia?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.4179):\u001b[0m\n",
            "‚Äã\n",
            " \n",
            "‚Äã\n",
            "Alto Desempenho com Custo Computacional Moderado O \n",
            "blip-vqa-base √© a vers√£o compacta da fam√≠lia BLIP\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m Por que o modelo Salesforce/blip-vqa-base foi escolhido?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.3993):\u001b[0m\n",
            "‚Äã\n",
            "O modelo Salesforce/blip-vqa-base foi escolhido por se \n",
            "apresentar como uma solu√ß√£o eficiente, leve e de alto \n",
            "desempenho para tarefas de Visual Question Answering \n",
            "(VQA) ‚Äî ou seja, ele √© capaz de interpretar informa√ß√µes \n",
            "contidas em imagens e fornecer respostas em linguagem \n",
            "natural a partir dessas informa√ß√µes\n",
            "\n",
            "\n",
            " --------------------------------------------------------------------------------\n",
            "\u001b[1müü• Pergunta:\u001b[0m Qual modelo de grande porte foi citado no texto como exemplo de alternativa mais robusta, por√©m mais pesada?\n",
            "\n",
            "\u001b[1müîπ Top 1 (Similaridade: 0.4850):\u001b[0m\n",
            "Multimodalidade \n",
            "Avan√ßada O BLIP (Bootstrapped Language-Image \n",
            "Pretraining) representa uma arquitetura multimodal moderna, \n",
            "projetada especificamente para integrar as √°reas de vis√£o \n",
            "computacional e processamento de linguagem natural\n",
            "\n"
          ]
        }
      ]
    }
  ]
}